{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AMERICAN SIGN LANGUAGE Recognition\n",
    "\n",
    "\n",
    "## *BY TEAM 17:*\n",
    "\n",
    "### *Tanuj Singhal*\n",
    "### *Tarun Kumar*\n",
    "### *Ankit Varshney*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](img/myimg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](img/img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Objective of this project is an attempt to a model to identify Static American sign language in real run time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem encountered during model:\n",
    "### Initially when we trained our Convolutional model on directly unprocessed real images model was stuck around accuracy of 40 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Steps to improve our model we took :\n",
    "\n",
    " ### *we took a real world dataset and did background subtration in it*\n",
    " ### *this improved our model's accuracy from around 40% to 80%*\n",
    " ### *To further imporve we data augmentation which is being done before feeding images to            train our model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some images after preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](img/A.png)\n",
    "![title](img/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "my_model = Sequential()\n",
    "my_model.add(Convolution2D(64, (3,  3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "my_model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "my_model.add(Convolution2D(32, (3,  3), activation = 'relu'))\n",
    "my_model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "my_model.add(Convolution2D(32, (3,  3), activation = 'relu'))\n",
    "my_model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dense(128, activation = 'relu'))\n",
    "my_model.add(Dense(26, activation = 'softmax'))\n",
    "my_model.compile(\n",
    "              optimizer = optimizers.SGD(lr = 0.01),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36400 images belonging to 26 classes.\n",
      "Found 6500 images belonging to 26 classes.\n",
      "Found 9100 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation and importing images from directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'mydata/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'mydata/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'mydata/training_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 401/1422 [=======>......................] - ETA: 2:49 - loss: 2.6050 - acc: 0.2322"
     ]
    }
   ],
   "source": [
    "# Fitting model\n",
    "model = my_model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=1422,\n",
    "        epochs=5,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 285\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# my_model.save('../asl_recognition_project/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Printing plots \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "plt.plot(model.history['acc'])\n",
    "plt.plot(model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# testing on an image\n",
    "import glob\n",
    "cnt=0\n",
    "target_names=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "czn=0\n",
    "cz=0\n",
    "net=0\n",
    "true=[0 for i in range(26)]\n",
    "false=[0 for i in range(26)]\n",
    "\n",
    "for i in target_names:\n",
    "  for name in glob.glob('../asl_recognition_project/mydata/test_set/'+str(i)+'/*'):\n",
    "  #     print(name)\n",
    "  #     cnt+=1\n",
    "    image_path=str(name)\n",
    "    test_image = image.load_img(image_path, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = my_model.predict(test_image)\n",
    "    if result[0][cnt]==1:\n",
    "      true[cnt]+=1\n",
    "    else:\n",
    "      false[cnt]+=1\n",
    "    net+=1\n",
    "  cnt+=1\n",
    "accuracy=sum(true)/net\n",
    "print(\"Accuracy=\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now we will move on to Real time sign detection which we have implemented from scratch using opencv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
